{\rtf1\ansi\ansicpg936\cocoartf2708
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset134 STSongti-SC-Regular;\f1\fnil\fcharset0 LucidaGrande;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red109\green109\blue109;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c50196\c50196\c50196;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0

\f0\fs29\fsmilli14667 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 With the increasing amount of available data, computing power and network speed for a decreasing cost, the manufacturing industry is facing an unprecedented amount of data to process, understand and exploit. Phenomena such as Big Data, the Internet-of-Things, Closed-Loop Product Lifecycle Management, and the advances of Smart Factories tend to produce humanly unmanageable quantities of data.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Human\'a8\'43robot collaboration (HRC) has attracted strong interests from researchers and engineers for improved operational flexibility and efficiency towards mass personalization. Nevertheless, existing HRC development mainly undertakes either human-centered or robot-centered manner reactively, where operations are conducted by following the pre-defined instructions, thus far from an efficient integration of robotic automation and human cognitions. The prevailing research on human-level information processing of cognitive computing, the industrial IoT, and robot learning creates the possibility of bridging the gap of knowledge distilling and information sharing between onsite operators, robots and other manufacturing systems. Hence, a foreseeable informatics-based cognitive manufacturing paradigm, Proactive HRC, is introduced as an advanced form of Symbiotic HRC with high-level cognitive teamwork skills to be achieved stepwise, including: (1) inter-collaboration cognition, estab\uc0\u173  lishing bi-directional empathy in the execution loop based on a holistic understanding of humans and robots\'a1\'af situations; (2) spatio-temporal cooperation prediction, estimating human\'a8\'43robot\'a8\'43object interaction of hierarchical sub-tasks/activities over time for the proactive planning; and (3) self-organizing teamwork, converging knowledge of distributed HRC systems for self-organization learning and task allocation. Except for the description of their technical cores, the main challenges and potential opportunities are further discussed to enable the readiness towards Proactive HRC.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Home-use glucose meters provide a simple real-time means for diabetic mellitus patients to monitor their blood sugar. However, there are still many interface design defects in current glucose meter products which can easily cause operation errors. The aim of this study is to identify the perceptional information of commercial home-use glucose meter interfaces for the elderly. First, three aspects of perception information of glucose meters was examined, consisting of the behavioral information (BI), assemblage information (AI), and conventional information (CI) of glucose meters. Then, five elderly test subjects older than 65 years who never used home-use glucose meters before were recruited to perform usability tests in order to identify perceptional information. The results demonstrated that five parts should be used, and nine assembly processes should be operated during glucose measurement. The application for assembly-disassembly ability is required for the part-part category; the AI and CI provide effective support for this application. The critical factors that may cause operation errors involved lancing devices and test strips rather than glucose meters. Possible reasons for this might arise from poor design of product perceptual information or unclear symbols. The conclusion is that product designers should provide more perception information, especially in terms of AI, to assist elderly users to understand how to use home-use medical devices such as glucose meters.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Home caring usually refers to taking care of the elder, the young kids and the patients at home, and this depends on both caregivers and caring systems. The system which can provide sufficient and accurate information to doctors or caregivers without a delay will bring benefits for all the persons who need to be cared and allow doctor or care givers to take right action based on the information immediately. Available corresponding products in the market mainly are some smart home devices or some medical facilities based on electroencephalo-graph (EEG), electrocardiograph(ECG) or blood pressure check, however, these parameters cannot give doctors, caregivers or family members a direct feedback. To address the problem, this paper introduces a deep learning based design - a visual recognition system developed for clinical monitoring which can supervise both the emotions and gestures of patients at the same time and give responsible persons instant and direct feedback so that the right treatment will be taken by them. This product uses a Raspberry Pi computer with its camera as hardware and implementing several deep learning models to fulfill three main functions which are: Facial Recognition, Emotion Detection and Pose Estimation onto a portable device, which enhances the utilization of theapplication and this brings more possibilities. Compared to theavailable products, this application emphasizes monitoring per-sons via visual analysis and gives more direct feedback all thetime instead of traditional ways which are not always timely orpractical.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 One of the most critical decision points in collaborative product development is final design concept selection. This crucial stage is considered as a complicated multicriteria decision-making problem which affects not only the subsequent design stages but the whole product lifecycle and supply chain. In fact, in addition to the fact that it is a knowledge intensive based phase, the information manipulated at this stage is mainly subjective and imprecise. Therefore, the aim of this paper is to propose a new fuzzy-ontology based approach to handle the vagueness and subjectivity in design concept evaluation and to support the decision making process at this phase. A case study is given to demonstrate the potential of the proposed methodology.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Weld evaluation processes are usually conducted in the post-weld stage. In this way, defects are found after the weld is completed, often resulting in disposal of expensive material or lengthy repair processes. Simultaneously, weld quality inspections tend to be performed manually by a human, even for an automated weld. Therefore, a proper real-time weld quality monitoring method associated with a decision-making strategy is needed to increase the productivity and automaticity in weld. In this study, acoustic emission (AE) as a real-time monitoring method is introduced for gas metal arc weld. The AE system is designed to cover a wide range of frequencies from 5 to 400 kHz. Additionally, the welding parameters (weld current, voltage, gas flow rate, and heat input) are recorded concurrently with AE. Different types of weld defects are artificially created to generate different signals. For the automated decision-making system, machine learning algorithms are used. Several features extracted from the AE and welding parameters feed into a machine learning algorithm. A new AE feature as the rate of AE energy accumulation extracted from time driven AE feature is defined. For decision-making, supervised learning models are trained and evaluated using testing data. General classification methods\'a1\'aasuch as Logistic Regression\'a1\'aapredict each datapoint separately. In this study, Adversarial Sequence Tagging method is applied to predict the presence of four weld states as good, excessive penetration, burn-through, porosity and porosity-excessive penetration. We explore the prediction task as a sequence tagging problem where the label of a data-point depends on its corresponding features as well as neighboring labels. When all the AE features as well as heat input are used in the feature set, the sequence tagging and logistic regression algorithms achieve a prediction accuracy of 91.18% and 82.35%, respectively, as compared to metallographic analysis.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Belief revision is an important task for designing intelligent systems. In the possibility theory framework, considerable work has addressed revising beliefs in a possibilistic logic framework while only few works have addressed a possibilistic revision process in graphical-based frameworks. In particular, belief revision of causal product-based possibilistic networks which are the possibilistic counterparts of probabilistic causal networks has not yet been addressed. This paper is concerned with revising causal possibilistic networks in presence of two kinds of information: observations and interventions (which are external actions forcing some variables to some specific values). It contains two contributions: we first propose an e
\f1 \uc0\u64259 
\f0 cient method for integrating and accepting new observations by directly transforming the initial graph. Then we highlight important issues related to belief revision of causal networks with sets of observations and interventions.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Project management (PM) capabilities define organizational abilities of delivering predictable project results in a changing environment. To increase maturity of the PM capabilities, they need to be formalized, aligned with standards and best practices, measured, controlled and improved. One of capabilities standardization and formalization approaches is to perform capability modelling. This paper proposes to use the Capability Driven Development methodology to model the PM capability models because this methodology allows for representing unique capability delivery context situations and specification of context-aware PM processes. The paper outlines the capability modelling processes and elaborates the capability model for the risk management sub-capability. Potential applications of the capability model are discussed.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 \cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Multi-view clustering, which exploits the multi-view information to partition data into their clusters, has attracted intense attention. However, most existing methods directly learn a similarity graph from original multi-view features, which inevitably contain noises and redundancy information. The learned similarity graph is inaccurate and is insufficient to depict the underlying cluster structure of multi-view data. To address this issue, we propose a novel multi-view clustering method that is able to construct an essential similarity graph in a spectral embedding space instead of the original feature space. Concretely, we first obtain multiple spectral embedding matrices from the view-specific similarity graphs, and reorganize the gram matrices constructed by the inner product of the normalized spectral embedding matrices into a tensor. Then, we impose a weighted tensor nuclear norm constraint on the tensor to capture highorder consistent information among multiple views. Furthermore, we unify the spectral embedding and low rank tensor learning into a unified optimization framework to determine the spectral embedding matrices and tensor representation jointly. Finally, we obtain the consensus similarity graph from the gram matrices via an adaptive neighbor manner. An efficient optimization algorithm is designed to solve the resultant optimization problem. Extensive experiments on six benchmark datasets are conducted to verify the efficacy of the proposed method. The code is implemented by using MATLAB R2018a and MindSpore library [1]: https: //github.com/guanyuezhen/CGL.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 A computer keyboard is an important human\'a8\'43machine interaction device. A key-cap and a keyboard are flexibly connected, and its assembly quality, especially flatness, is crucial. In manufacturing quality control, the requirement for assembly quality of keyboards is quite strict, where the flatness measurement of key-caps is a key link. In this paper, an apparatus based on multi-line structured light imaging, and machine vision is designed for online rapid detection of keycap flatness, is proposed. First, a novel 3D measurement scheme is presented to replace the complete 3D surface reconstruction of conventional methods. Then, an array of cameras with a perspective projection transformation matrix calibration approach is adopted to expand the scanning range of the 3D sensor for largescale and high-resolution target imaging. In addition, a multi-step image processing is applied to accurately extract the centerline of the projected fringes on a key-cap with printed character, which indirectly helps to improve the measurement accuracy. Finally, a sparse sampling flatness estimation algorithm is proposed to improve the detection efficiency. According to experiments in real production lines, our apparatus can achieve a detection accuracy of 99.74% for various computer keyboards.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 This paper presents an ongoing multi-disciplinary research-and development project in which we are exploring emerging methods and practices for participatory design of tools and content of accessibility information in India and Sweden, based on user created content. The initial development of the AUGMENT-Project also includes the production of a prototype for sharing information. The joint set up and unfolding of public digital spaces and cooperative creation of processes and infrastructure for user-driven accessibility information is making use of existing handheld mobile phones which offer the possibility to upload pictures and comments via an application with a mapbased interface. The research initiative is exploring and comparing crosscultural participatory methods for cultivation of shared transformational spaces. The paper discusses both the notion of user-driven content and co-creation of tools and methods, drawing upon the tradition of Scandinavian Systems Design, explicitly arguing for direct user-representation in systems development.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 \cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 The automotive industry is facing a change from combustion engine-powered to electrified vehicles. Besides the traction battery, the electric engine is one of the most important components of the electrified powertrain. In order to increase the energy efficiency of the electric motor, wound copper wires are replaced by enameled rectangular copper wires, known as hairpins. In order to produce a conductive connection between hairpins, it is necessary to weld them together. Currently, the automated laser welding of copper is a poorly understood process. Such new production processes are still unknown in comparison to classic engine production and there is only little expert knowledge available. The integration of Industry 4.0 techniques and advanced data analytics provides the opportunity to understand the process of copper welding more thoroughly. A common understanding of advanced data analytics differentiates between predictive and prescriptive analytics. One of the most promising developments in advanced analytics is Machine Learning (ML). There is a wide range of different types of algorithms, theories and methods. An example of these are Convolutional Neural Networks (CNN). They have been designed for learning multidimensional data, such as images or even videos. This paper presents such a CNN to detect welding defects of hairpins. Depending on the classified defect, a rework concept is given (prescriptive analytics). The input parameters are the visual information are derived from of a 3D camera. Using the welding process as an example, the paper illustrates a newly developed method based on the CRoss Industry Standard Process for Data Mining (CRISP-DM) for the development of the CNN. In this context, the paper deals in detail with data preprocessing, modeling and evaluation. The newly developed methodology and architecture of the CNN achieves an accuracy of over 99 percent to predict the defect class.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Deep digitization drives value because it enables the exploitation of computational techniques to solve hard problems inherent to industrial enterprises. This includes product design, processes and procedures used in industrial settings tools and methods for manufacturing, and product maintenance, repair and overhaul. This paper will cover what is meant by deep digitization, review the thinking that has brought us to where we are today and look at the challenges and options that lay ahead. It will also describe what is meant by industrial transformation and identify the stakeholders and markets involved.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Design research is an important work in product design. Through a series of data collection and data analysis, we can better adjust the design scheme. The traditional product design research mode data analysis effect is not good, through the Big Data(BD) technology research and analysis of product design, is a good solution at present. Therefore, this paper establishes the research on the influence and application of BD analysis in product design research. In this paper, the product design research and the application of BD analysis technology in the design research are deeply studied and analyzed. It is believed that through the BD technology, the research content can be analyzed more scientifically, so as to improve the overall product design effect. In order to make the BD analysis technology better applied in product design research, this paper optimizes and improves the evaluation crowd weight calculation method of entropy processing, which effectively improves the accuracy of the algorithm. In order to further verify the application effect of BD analysis in product design research; this paper establishes a test experiment with "mobile power supply" as the product. The experimental results show that among the tested users, young people aged 15-20 are the main ones, accounting for 38.7%. According to the analysis of users' interests and hobbies, the highest proportion of digital options is 31.2%. The analysis shows that the results of BD analysis provide valuable reference for the formulation and adjustment of product design strategy.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 The development of a new product can be accelerated by using an approach called crowdsourcing. The engineers compete and try their best to provide the related solution based on the given product requirement submitted in the online crowdsourcing platform. The one who has submitted the best solution get a financial reward. This approach is proven to be three time faster than the conventional one. However, the crowdsourcing process is usually not transparent to a new user. The risk for the execution of a new project for developing a new product is not easy to be calculated [1, 2]. We developed a method InnoCrowd to handle this problem and the new user could use during the planning of a new product development project. This system uses AI concepts to generate a knowledgebase representing histories of successful product development projects. The system uses the knowledge to determine qualitative and quantitative risks of a new project. This paper describes the new method, the InnoCrowd design, and results of a validation experiment based on data from a current crowdsourcing platform. Finally, we compare InnoCrowd to related methods and systems in terms of design and benefits.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Recent years have witnessed a great deal of enthusiasm devoting to big data analytics systems, some of them, with the property of high scalability and fault tolerance, are extensively used in real productions. However, such systems are mostly designed for processing immutable data stored in HDFS, not suitable for real-time text data in NoSQL database like HBase. In this paper, we propose a search-e
\f1 \uc0\u64259 
\f0 cient hybrid storage system termed LuBase for large-scale text data analytics scenarios. Not just a novel hybrid storage system with fine-grained index, LuBase also presents a new query process flow which can fully employ pre-built full-text index to accelerate the execution of interactive queries and achieve more e
\f1 \uc0\u64259 
\f0 cient I/O performance at the same time. We implemented LuBase in a data analytics system based on Impala. Experimental results demonstrate that LuBase can reap huge fruits from Lucene index technique and bring significant performance improvement for Impala when querying HBase.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 User eXperience (UX) is becoming increasingly important for success of software products. Yet, many companies still face various challenges in their work with UX. Part of these challenges relate to inadequate knowledge and awareness of UX and that current UX models are commonly not practical nor well integrated into existing Software Engineering (SE) models and concepts. Therefore, we present a conceptual UX-aware model of requirements for software development practitioners. This layered model shows the interrelation between UX and functional and quality requirements. The model is developed based on current models of UX and software quality characteristics. Through the model we highlight the main differences between various requirement types in particular essentially subjective and accidentally subjective quality requirements. We also present the result of an initial validation of the model through interviews with 12 practitioners and researchers. Our results show that the model can raise practitioners\'a1\'af knowledge and awareness of UX in particular in relation to requirement and testing activities. It can also facilitate UX-related communication among stakeholders with different backgrounds.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 This paper proposes a new methodology for developing a computerbased design system. It places designers at the centre of design process to perform their tasks collaboratively with the design system. The proposed system is developed based on interactive shape grammar and evolutionary design algorithm, which is able to increase the creativity and productivity of design activity. Designers can utilize the generated designs to initialize their conceptual design process more easily and rapidly. The source of form diversity is derived from genetic operators. Subjective user preference is used for design evaluation. The system can be integrated with computer-controlled model-making machines to automatically build physical artifacts. As a result, designers can easily start their conceptual design process through obtaining the desired designs and the resulting physical artifacts in line. The human-computer synergy is illustrated for the design of jewelry, but it is applicable to other industrial product design problems.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 This paper seeks to address the decision making problem in software development outsourcing scenarios in which a project manager is in charge of deciding about which software components will be outsourced and which ones will be developed internally. Therefore we propose a methodology and tool support which leverage the classification of a project\'a1\'afs software components by means of a graph-based model of the components\'a1\'af requirements and their corresponding clustering. In the course of our design oriented research approach, a prototypical implementation of the methodology has been developed and evaluated. It illustrates the practical applicability of the proposed method. We thereby contribute to the location selection problem in distributed software projects and give guidance for in-house or external software production. The theoretical contribution consists of revealing an improved processing methodology for assessing software requirements and increasing the outsourcing success of a software project. Our contribution for practice is an implemented prototype for project leads of distributed teams.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Recently, by exploiting asymmetric learning mechanism, asymmetric hashing methods achieve superior performance in image retrieval. However, due to the discrete binary constraint, these methods typically rely on a special optimization strategy of discrete cyclic coordinate descent (DCC), which is time-consuming since it must learn the binary codes bit by bit. To address this problem, we propose a novel deep supervised hashing method called Fast Deep Asymmetric Hashing (FDAH), which learns the binary codes of training and query sets in an asymmetric way. FDAH designs a novel asymmetric hash learning framework using the inner product of the output of deep network and semantic label regression to approximate the similarity and minimize the discriminant reconstruction error between the deep representation and the binary codes. Instead of using the DCC optimization strategy, FDAH avoids using the quadratic term of binary variables and the binary code of all bits can be optimized simultaneously in one step. Moreover, by incorporating the semantic information in binary code learning and the quantization process, FDAH can obtain more discriminative and e
\f1 \uc0\u64259 
\f0 cient binary codes. Extensive experiments on three well-known datasets show that the proposed FDAH can achieve state-of-the-art performance with less training time.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Ever since the advent of AlexNet, designing novel deep neural architectures for different tasks has consistently been a productive research direction. Despite the exceptional performance of various architectures in practice, we study a theoretical question: what is the condition for deep neural architectures to preserve all the information of the input data? Identifying the information lossless condition for deep neural architectures is important, because tasks such as image restoration require keep the detailed information of the input data as much as possible. Using the definition of mutual information, we show that: a deep neural architecture can preserve maximum details about the given data if and only if the architecture is invertible. We verify the advantages of our Invertible Restoring Autoencoder (IRAE) network by comparing it with competitive models on three perturbed image restoration tasks: image denoising, JPEG image decompression and image inpainting. Experimental results show that IRAE consistently outperforms non-invertible ones. Our model even contains far fewer parameters. Thus, it may be worthwhile to try replacing standard components of deep neural architectures with their invertible counterparts. We believe our work provides a unique perspective and direction for future deep learning research.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Sentiment analysis can be performed using machine learning algorithms to automatically identify the sentiment associated with reviews about products or services available online. In many sentiment analysis practical scenarios, it is necessary to classify reviews in rates between 1 to 5 stars \'a8\'43 a multiclass problem. In literature, we found that the best results for reviews classification are those who propose solutions based on binary splits, achieving accuracies above 90 %. As such, we propose a model, based on the Nested Dichotomies algorithm, that performs multiclass classification in successive steps of binary classification operations. For this classifier to be more effective, we propose that the first split should be defined by identifying users\'a1\'af recommendation threshold. We present a case study in which this classification model is applied to a set of subjective data extracted from TripAdvisor, discuss the process of determining the first split and evaluate the accuracy of the proposed model.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 In this paper the authors have presented the design and implementation of Edutactile, a cross-platform software which automates the process of creation of tactile diagrams. Edutactile provides for automated application of guidelines or presets as well as Braille translation and thus abstracts away the production related issues. This relieves special educators for the visually challenged from having to learn the workings of the graphics editing software (Photoshop, CorelDraw) which are currently being used to produced tactile graphics and instead focus on the content of the diagram.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Test compaction is an important aspect in the postproduction test since it is able to reduce the test data and the test costs, respectively. Current automatic test pattern generation (ATPG) methods treat all faults independently from each other which limits the test compaction capability. We propose a new optimization satisfiability (SAT)-based ATPG for compact test set generation with high fault coverage as well as a new retargeting stage for test set reduction. The ATPG is based on a novel multiple-target test generation formulation using optimization techniques. Robust SAT-based solving algorithms are leveraged to determine compatible fault groups which can be detected by the same test. The proposed technique can be used during initial compact test generation as well as a post-process to increase the compactness of existing test sets, e.g., generated by commercial tools, in an iterative manner. Experimental results show that the proposed SAT-based approach is able to produce highly compacted test sets with high fault coverage for stuck-at as well as transition faults. The approach is able to produce lower pattern counts than a commercial ATPG tool. For one industrial circuit, the test set size can even be reduced down to 26% of the size generated by a commercial ATPG tool.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Sentiment Analysis tools, developed for analyzing social media text or product reviews, work poorly on a Software Engineering (SE) dataset. Since prior studies have found developers expressing sentiments during various SE activities, there is a need for a customized sentiment analysis tool for the SE domain. On this goal, we manually labeled 2000 review comments to build a training dataset and used our dataset to evaluate seven popular sentiment analysis tools. The poor performances of the existing sentiment analysis tools motivated us to build SentiCR, a sentiment analysis tool especially designed for code review comments. We evaluated SentiCR using one hundred 10fold cross-validations of eight supervised learning algorithms. We found a model, trained using the Gradient Boosting Tree (GBT) algorithm, providing the highest mean accuracy (83%), the highest mean precision (67.8%), and the highest mean recall (58.4%) in identifying negative review comments.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Customer opinion holds a very important place in products and service business, especially for companies and potential customers. In the last years, opinions have become yet more important due to global Internet usage as opinions pool. Unfortunately , looking through customer reviews and extracting information to improve their service is a di
\f1 \uc0\u64259 
\f0 cult work due to the large number of existing reviews. In this work we present a system designed to mine client opinions, classify them as positive or negative, and classify them according to the hotel features they belong to. To obtain this classification we use a machine learning classifier, reinforced with lexical resources to extract polarity and a specialized hotel features taxonomy.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Artificial Intelligence (AI) systems applications are widespread due to its domain independent characteristics. In this work, an attempt has been made for review on AI applications in Computer Aided Process Planning (CAPP) and manufacturing. Primarily, uniqueness of present review work addressed by analysis of existing review articles. The review work comprise of three main elements; 1. Feature based design, a primary input for a CAPP system, 2. Expert System (ES) usefulness in Process Planning (PP) and manufacturing and 3. Evolutionary approach applications. The review begins with an overview and the use of AI systems in decision making. Research works exemplified for the past three and half decades (1981\'a8\'432016) are analyzed in terms of feature based modeling, Standards for Exchange of Product Model data approach, ES in PP, scheduling, manufacturing and miscellaneous applications. Role of Evolutionary Techniques (ET) in intelligent system development, execution of PP activities and manufacturing are described. A statistical analysis on existing review articles, number of publications, domain specific articles and percentage contribution of each area are carried out. Finally, research gaps are identified and the possible future research directions are presented.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 \cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Websites of home-interior brands display many photographs of products that include walls, floors, and furniture. Such photographs, known as image photographs, contain a lot of information about the brand image because the colors of walls, floors, and furniture in a photograph influence the brand image. This paper proposes a method of extracting representative colors of interior photographs by using a hierarchical clustering algorithm and analyzes the characteristics and differences of interior brands with color features. Our proposed method can be used to describe the common characteristics of interior image photographs and differences between eight interior brands (Ralph Lauren Home, Herman Miller, arflex, Cassina, Carl Hansen and Son, IKEA, Karimoku and Nitori). We measure the similarity or difference between brand images by constructing a brand image space with clusters of representative colors and obtain the relationship between six brand images.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 The central objective of the present author\'a1\'afs research is to develop a system supporting the design of a technological process (a computer-aided process planning system) that functions similarly to a human expert in the field in question. The use of neural networks makes the creation of such a system possible. The proposed method uses a system of three blocks of neural networks, and involves the creation of neural networks to be used for the selection of machines, tools, and machining parameters. These networks are built for each process operation separately; that is, a set of neural networks is created for each selection. For the construction of models, different types of neural networks (multilayer networks with error backpropagation, radial basis function, and Kohonen) with different structures were employed, and the networks that made the best selections were identified. A method was also developed for the elimination of defects occurring during the production process. When a defect comes to light, this method suggests changes to the technological process, thus improving the quality of that process. Guidelines for the elimination of defects are produced in the form of decision rules. Such a computeraided process planning system will be especially useful for process engineers who do not yet have sufficient experience in the design of technological processes, or who have only recently joined a particular manufacturing enterprise and are not fully familiar with its machines and other means of production (tools and instrumentation). It should be emphasized that such a system performs an advisory role, and it is always the process engineer who makes the final decision. The neural network models were tested on real data from an enterprise. A computer-aided process planning system based on rules and neural network models enables the intelligent design of technological processes.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 The rapid growth of the Chinese consumer market has created a demand for new Chinese fit wearable products. The industry requires accurate digital data on Chinese head and facial shapes to develop new consumer products. 3D head models that express the dimension of Chinese head anthropometry are of great importance in various product design processes. Previous 3D statistical models were fitted mostly using dimensional frames made by head and facial landmarks that cannot adequately demonstrate the complex facial geometry. This paper proposed a 3D head fitting method for the 5th, 25th, 50th, 75th and 95th percentiles using a progressive scanning algorithm based on differential approximation. The high-precision point cloud data obtained were transformed into mesh models, and the facial details were integrated and improved by 3D facial feature frameworks and artistic digital sculpting. The 3D digital models and 3D printing models with different percentiles constructed in this research can be utilized as design-aided tools for physiological comfort optimization in wearable products design and other ergonomic evaluation procedures.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 As a milestone product of the AI era, the autonomous vehicle has attracted tremendous attention from the whole society. When autonomous vehicles (AV) provide transportation services as passenger vehicles in the future, a comfortable riding experience will be the fundamental element of usability. In such a case, it is necessary to establish an objective and sound evaluation system to evaluate the comfort level of autonomous vehicles. We hereby develop the comfort level model of autonomous vehicles with the following three steps: (a) Explore subjective evaluation indicators: Invite passengers to test autonomous vehicles and collect their ratings of the comfort level; (b) Establish the subjective comfort evaluation model: classify the evaluation indicators, continuously collect the evaluation data of the comfort level from the passengers during the testing process, and then use the structural modelling method to form a subjective evaluation model of the comfort level; (c) Develop the automatic scoring tool: collect subjective and objective data through data collection apps, form a calculation function with machine learning algorithm that fits the subjective and objective data, and develop an automatic scoring tool based on it. This precisely developed evaluation system and the empirical data-based scoring tool can be used to guide technological development, optimize algorithms, and improve strategies within the AV corporate. On the other hand, it can help to unify evaluation standard for AV industry, improving the experience of autonomous vehicle rides.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 In e-commerce websites, user-generated question-answering text pairs generally contain rich aspect information of products. In this paper, we address a new task, namely Question-answering (QA) aspect classification, which aims to automatically classify the aspect category of a given QA text pair. In particular, we build a high-quality annotated corpus with specifically designed annotation guidelines for QA aspect classification. On this basis, we propose a hierarchical attention network to address the specific challenges in this new task in three stages. Specifically, we firstly segment both question text and answer text into sentences, and then construct (sentence, sentence) units for each QA text pair. Second, we leverage a QA matching attention layer to encode these (sentence, sentence) units in order to capture the aspect matching information between the sentence inside question text and the sentence inside answer text. Finally, we leverage a self-matching attention layer to capture different importance degrees of different (sentence, sentence) units in each QA text pair. Experimental results demonstrate that our proposed hierarchical attention network outperforms some strong baselines for QA aspect classification.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 To discover semantically coherent topics from topic models, knowledge-based topic models have been proposed to incorporate prior knowledge into topic models. Moreover, some researchers propose lifelong topic models (LTM) to mine prior knowledge from topics generated from multi-domain corpus without human intervene. LTM incorporates the learned knowledge from multi-domain corpus into topic models by introducing the Generalized Polya Urn (GPU) model into Gibbs sampling. However, GPU model is nonexchangeable so that topic inference for LTM is computationally expensive. Meanwhile, variational inference is an alternative approach to Gibbs sampling and tend to be faster than Gibbs sampling. Moreover, variational inference can also be flexible for inferring topic models with knowledge, i.e., regularized topic model. In this paper, we propose a fast and effective framework for lifelong topic model, called Regularized Lifelong Topic Model with Self-learning Knowledge (RLTMSK), with lexical knowledge automatically learnt from the previous topic extraction, then design a variational inference method to estimate the posterior distributions of hidden variables for RLTM-SK. We compare our method with 5 state-of-the-art baselines on a dataset of product reviews from 50 domains. Results show that the performance of our method is comparable to LTM and other knowledge-based topic models. Moreover, our model is consistently faster than the best baseline method, LTM.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Motion capture (MoCap) is the technology of capturing the movement of a target through sensors such as optical equipment or inertial measurement units. It is widely used in industrial fields. In this work, a robot learning from demonstration platform is established including motion capturing, data pre-processing, policy learning, and a robot controller. It takes the optical MoCap system as the sensor to acquire the motion data of the target. Since the data obtained through the MoCap system always suffer from problems such as noise and data loss, a data processing strategy that can be divided into data pre-processing and policy learning is proposed to obtain a smooth robot motion trajectory. Then the robot trajectory will be transmitted to the designed robot controller to drive a real robot. The proposed robot learning from demonstration platform, which is designed for the rapid deployment of robots in industrial production lines, is convenient for secondary development and enables non-robotics professionals to operate the robots easily.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Objectives 4 Provide an explicit statement of questions being addressed with reference to participants, interventions, comparisons, outcomes, and study design (PICOS). METHODS Protocol 5 Indicate if a review protocol exists, if and where it can be accessed (e.g., Web address), and registration and, if available, provide registration information including registration number. Eligibility criteria 6 Specify study characteristics (e.g., PICOS, length of follow-up) and report characteristics (e.g., years considered, language, publication status) used as criteria for eligibility, giving rationale. Information sources 7 Describe all information sources (e.g., databases with dates of coverage, contact with study authors to identify additional studies) in the search and date last searched. Search 8 Present full electronic search strategy for at least one database, including any limits used, such that it could be repeated. Study selection 9 State the process for selecting studies (i.e., screening, eligibility, included in systematic review, and, if applicable, included in the meta-analysis). Data collection process 10 Describe method of data extraction from reports (e.g., piloted forms, independently, in duplicate) and any processes for obtaining and confirming data from investigators. Data items 11 List and define all variables for which data were sought (e.g., PICOS, funding sources) and any assumptions and simplifications made. Risk of bias in 12 Describe methods used for assessing risk of bias of individual studies individual studies (including specification of whether this was done at the study or outcome level), and how this information is to be used in any data synthesis. Summary measures 13 State the principal summary measures (e.g., risk ratio, difference in means). Synthesis of results 14 Describe the methods of handling data and combining results of studies, if done, including measures of consistency (e.g., I2) for each meta-analysis. Risk of bias 15 Specify any assessment of risk of bias that may affect the cumulative evidence across studies (e.g., publication bias, selective reporting within studies). Additional analyses 16 Describe methods of additional analyses (e.g., sensitivity or subgroup analyses, metaregression), if done, indicating which were pre-specified. RESULTS Study selection 17 Give numbers of studies screened, assessed for eligibility, and included in the review, with reasons for exclusions at each stage, ideally with a flow diagram. Study characteristics 18 For each study, present characteristics for which data were extracted (e.g., study size, PICOS, follow-up period) and provide the citations. Risk of bias 19 Present data on risk of bias of each study and, if available, any outcome-level assessment within studies (see Item 12). Results of 20 For all outcomes considered (benefits or harms), present, for each study: (a) simple summary individual studies data for each intervention group and (b) effect estimates and confidence intervals, ideally with a forest plot. Synthesis of results 21 Present results of each meta-analysis done, including confidence intervals and measures of consistency. Risk of bias across studies 22 Present results of any assessment of risk of bias across studies (see Item 15). Additional analysis 23 Give results of additional analyses, if done (e.g., sensitivity or subgroup analyses, meta-regression [see Item 16]). DISCUSSION Summary 24 Summarize the main findings including the strength of evidence for each main of evidence outcome; consider their relevance to key groups (e.g., health care providers, users, and policy makers). Limitations 25 Discuss limitations at study and outcome level (e.g., risk of bias), and at review level (e.g., incomplete retrieval of identified research, reporting bias). Conclusions\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 \cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Design thinking has been a popular topic among the forward-thinking technology and business scenes. Even universities have joined the trend of adopting design thinking as a tool for innovation. While its popularity has opened up new and exciting opportunities for all design professions, when design thinking is packaged as a strategy to deliver innovation it is often implemented like a linearly gated step-by-step process. Thus the value and effectiveness of creativity offered in design thinking is weakened and the results are incremental at best. In these cases, designers, design consultancies, educators as well as business strategy firms have separated the tools and methods of design thinking from the mastery needed to use them. A designer\'a1\'afs creative process is iterative, messy, uncertain, and often leads to failed attempts and frustration. These characteristics are inherent to its organic nature, but ambiguity and learning from failures often lead to opportunities to innovate past the comfort of certainty and status quo. In an attempt to develop an organized and reliable design thinking process for the business culture, we have diluted the role of the designer as the expert capable of navigating, managing and leveraging opportunities from the creative challenge. This design mastery is a necessary component to successful innovation teams just as much as mastery with analytical tools and processes, verbal communication, technology and business. This paper offers insight into the adoption of design thinking at a large university in the United States. The authors interviewed students and faculty from Design, Engineering, and Business who have participated on multidisciplinary teams seeking innovation. Though disciplinary tools and methods are successfully borrowed or adapted within multiple fields, this paper suggests that the discipline-based mastery of skills is essential for those tools and methods to be used to their fullest potential.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 In the last few years, \'a1\'b0Design Thinking\'a1\'b1 has gained popularity e it is now seen as an exciting new paradigm for dealing with problems in sectors as far a field as IT, Business, Education and Medicine. This potential success challenges the design research community to provide unambiguous answers to two key questions: \'a1\'b0What is the core of Design Thinking?\'a1\'b1 and \'a1\'b0What could it bring to practitioners and organisations in other fields?\'a1\'b1. We sketch a partial answer by considering the fundamental reasoning pattern behind design, and then looking at the core design practices of framing and frame creation. The paper ends with an exploration of the way in which these core design practices can be adopted for organisational problem solving and innovation. \uc0\u211  2011 Elsevier Ltd. All rights reserved.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Ensemble learning combines several individual models to obtain better generalization performance. Currently, deep learning architectures are showing better performance compared to the shallow or traditional models. Deep ensemble learning models combine the advantages of both the deep learning models as well as the ensemble learning such that the final model has better generalization performance. This paper reviews the state-of-art deep ensemble models and hence serves as an extensive summary for the researchers. The ensemble models are broadly categorized into bagging, boosting, stacking, negative correlation based deep ensemble models, explicit/implicit ensembles, homogeneous/heterogeneous ensemble, decision fusion strategies based deep ensemble models. Applications of deep ensemble models in different domains are also briefly discussed. Finally, we conclude this paper with some potential future research directions.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Deep learning, a branch of machine learning, is a frontier for artificial intelligence, aiming to be closer to its primary goal\'a1\'aaartificial intelligence. This paper mainly adopts the summary and the induction methods of deep learning. Firstly, it introduces the global development and the current situation of deep learning. Secondly, it describes the structural principle, the characteristics, and some kinds of classic models of deep learning, such as stacked auto encoder, deep belief network, deep Boltzmann machine, and convolutional neural network. Thirdly, it presents the latest developments and applications of deep learning in many fields such as speech processing, computer vision, natural language processing, and medical applications. Finally, it puts forward the problems and the future research directions of deep learning.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 A large volume of product online reviews are generated from time to time, which contain rich information regarding customer requirements. These reviews help designers to make exhaustive analyses of competitors, which is one indispensable step in market-driven product design. How to extract critical opinionated sentences associated with some specific features from product online reviews has been investigated by some researchers. However, few of them examined how to employ these valuable resources for competitor analysis. Hence, in this research, a framework is illustrated to select pairs of opinionated representative yet comparative sentences with specific product features from reviews of competitive products. With the help of the techniques on sentiment analysis, opinionated sentences referring to a specific feature are first identified from product online reviews. Then, information representativeness, information comparativeness and information diversity are investigated for the selection of a small number of representative yet comparative opinionated sentences. Accordingly, an optimization problem is formulated, and three greedy algorithms are proposed to analyze this problem for suboptimal solutions. Finally, with a large amount of real data from Amazon.com, categories of extensive experiments are conducted and the final encouraging results are realized, which prove the effectiveness of the proposed approach.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Abstract Understanding customer behavior and driving customer satisfaction are necessary for any business to succeed in the competing mUnardkeerts.taCnodminpganciuesstonmeeedr tboebheavaiworaraenodfdthrievipnrgevcauislitnogmceursstoatmisefracpteiorcnepartieonsectoesmsaarkyefmoroarenyacbcuusriantesasntdo esfufcecetievde ipnlatnhsefcoormprpoedtiuncgt mdeavrekleotp. mCoenmtpaanndiesmnaerkedettiongb.eCauwsatoremoefrthfeepdrbeavcakiliinsgacvuasiltaobmlertpherorcuegphtiomnusltioplmeackheamnnoerles.acScpuercaitfeicaanldlye, fwfeectiavre pinlatenrsefsoterdprionduthcet udnevsterluocptmureendt daantda amvaariklaebtilnega.sCteuxstotmhaetr wfeoeudlbdabcek aisvaaivlaabilaebtlherothurgohugshocmiaul lmtipeldeiac,hcaonmnemlse.nStspfercoimficallsyu,rvweey,avreoiicneterreecsoterdiningsthoef ucunstorumceturriendtedractatioanvsa,ilaanbdlechaasttterxatnsthcaritpwtso. uAlndablyezainvgaislaubclhedtahtraoucogrhrescotclyiailsmcreidtiicaa,l,coasmimt reenvtesaflrsoemvearystuhrinvgeyf,rovmoicbeuyreincgortdreinngdss otof pcurosdtoumctefrlainwtesrancdtiopnrso,vaidnedscahasitgtnraifnisccarnitpbtsu.sAinneaslsyazdinvgansutacghe.dIattawcoourlrdecfutlrythisercsrtirtiecnagl,thaesnitbruesvineaelssseovpeproyrtthuinigtyfrtoomunbcuoyvinergcturesntodms etor ipnrtoedreuscttsf,lapwrosdauncdt ipmropvroidveesmaesnitgsn, iafincdanmt abrukseitniensgs iandsvigahntsa.gIen. Itthwisopualdpefru,rwtheresxtprelonrgethdeinffberuesnint etseschonpoploorgtuiensitoyftoDueenpcoLvearrcnuinstgomanedr NinateturersatlsL, apnrogduuacgteiPmropcroevsseimngen(tNs,LaPn)dthmatarwkoeutilndghienlspigahntasl.yIzne tbheitstepratpheer,cowneteexxtpulaolrienfdoirfmfearetinotntetochcnaopltougreiecsuostfoDmeeerpfeLeedabrancikn.g and Natural Language Processing (NLP) that would help analyze better the contextual information to capture customer feedback.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 The increasing number of product reviews posted online is a gold mine for designers to know better about the products they develop, by capturing the voice of customers, and to improve these products accordingly. In the meantime, product design and development have an essential role in creating a more sustainable future. With the recent advance of artificial intelligence techniques in the field of natural language processing, this research aims to develop an integrated machine learning solution to obtain sustainable design insights from online product reviews automatically. In this paper, the opportunities and challenges offered by existing frameworks \'a8\'43including Python libraries, packages, as well as state-of-the-art algorithms like BERT \'a8\'43 are discussed, illustrated, and positioned along an ad hoc machine learning process. This contribution discusses the opportunities to reach and the challenges to address for building a machine learning pipeline, in order to get insights from product reviews to design more sustainable products, including the five following stages, from the identification of sustainability-related reviews to the interpretation of sustainable design leads: data collection, data formatting, model training, model evaluation, and model deployment. Examples of sustainable design insights that can be produced out of product review mining and processing are given. Finally, promising lines for future research in the field are provided, including case studies putting in parallel standard products with their sustainable alternatives, to compare the features valued by customers and to generate in fine relevant sustainable design leads.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Online product reviews are a valuable resource for product developers to improve the design of their products. Yet, the potential value of customer feedback to improve the sustainability performance of products is still to be exploited. The present paper investigates and analyzes Amazon product reviews to bring new light on the following question: \'a1\'b0What sustainable design insights can be identified or interpreted from online product reviews?\'a1\'b1. To do so, the top 100 reviews, evenly distributed by star ratings, for three product categories (laptop, printer, cable) are collected, manually annotated, analyzed and interpreted. For each product category, the reviews of two similar products (one with environmental certification and one standard version) are compared and combined to come up with sustainable design solutions. In all, for the six products considered, between 12% and 20% of the reviews mentioned directly or indirectly aspects or attributes that could be exploited to improve the design of these products from a sustainability perspective. Concrete examples of sustainable design leads that could be elicited from product reviews are given and discussed. As such, this contribution provides a baseline for future work willing to automate this process to gain further insights from online product reviews. Notably, the deployment of machine learning tools and the use of natural language processing techniques to do so are discussed as promising lines for future research.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 The increasing use of online retail platforms has generated an enormous amount of textual data on the user experiences with these products in online reviews. These reviews provide a rich resource to elicit customer requirements for a category of products. The recent research has explored this possibility to some extent. The study reported here investigates the coding of publically available user reviews to understand customer sentiments on environmentally-friendly products. The manual review typically consists of a qualitative analysis of textual content, which is a resource-intensive process. An automated procedure based on Aspect-Based Sentiment Analysis (ABSA) is proposed and explored in this study. This procedure can be beneficial in analyzing reviews of products that belong to a specific category. As a case study, environmentally-friendly products are used. Manual content analysis and automated ABSA-based analysis are performed on the same review data to extract customer sentiments. The results show that we obtain over a 50% classification accuracy for a multiclass classification NLP task with a very elementary word vector-based model. The drop in accuracy (compared to human annotation) can be offset because an automated system is thousands of times faster than a human. Given enough data, it will perform better than its human counterpart in tasks on customer requirement modeling. We also discuss the future routes that can be taken to extend our system by leveraging more sophisticated paradigms and substantially improving our system's performance. Copyright \uc0\u169  2021 by ASME.\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trwWidth28449\trftsWidth3 \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth28409\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 Agricultural sector is desperately in need of engineering outcomes such as Automation, Information Technology and more recently Robotic Technology. Cotton Cultivation in India occupying a big share in commercial crops is facing a major problem of picking the cotton from the plants by the labor as the labor costs are increasing these days. This paper aims at achieving a prominent solution with the use of Machine vision together with Image Processing and Microcontrollers for identification, recognition, and processing of the cotton image as such and picking the cotton with robotic arms to yield maximum production in a day per hectare. Research and development in perceptual system for robots enabled the agricultural sector to catch hold of the technology in reducing the overall cost. These intelligent robots use variety of visual sensors to detect objects with respect to their identity, position, color, orientation in 3D pattern at the fields. This paper also proposes at the new algorithms in Image processing of the cotton to extract the feature, modeling and matching. These are Artificial Intelligence for Robotic Vision, Image Processing for Segmentation, feature measurement such as invariants, size and shape, texture and scene analysis and controlling the robotic arms in desired angle.\cell \lastrow\row
}